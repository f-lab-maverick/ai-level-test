{
  "version": "8.5.2",
  "description": "F-Lab AI 역량 진단 테스트 - 최종 25문항(통합 및 검수판)",
  "total_questions": 25,
  "estimated_time": "제한 없음",
  "notes": "v8.5.2: 부자연스러운 문장 수정, 정답 길이 편향 제거, 기술 검증 완료",
  "questions": {
    "Q1": {
      "id": "Q1",
      "level": 1,
      "title": "LLM의 한계",
      "question": "다음 중 LLM 단독(외부 도구 미연동)으로 수행하기 어려운 작업은?",
      "options": [
        {
          "id": "A",
          "text": "긴 문서를 읽고 핵심 내용 요약"
        },
        {
          "id": "B",
          "text": "주어진 텍스트를 다른 언어로 번역"
        },
        {
          "id": "C",
          "text": "오늘 기준 실시간 환율 조회"
        },
        {
          "id": "D",
          "text": "코드 리뷰 후 버그 가능성 지적"
        }
      ],
      "correct_answer": "C",
      "explanation": "LLM 단독은 학습 시점 이후의 실시간 외부 데이터에 접근하지 못합니다. 환율·날씨 등 최신 정보는 Function Calling이나 외부 검색/RAG가 결합되지 않으면 정확히 제공할 수 없습니다.",
      "learning_point": "LLM의 내재적 한계(실시간 데이터, 정밀 계산, 최신성)는 외부 도구로 보완한다."
    },
    "Q2": {
      "id": "Q2",
      "level": 1,
      "title": "프롬프트 기본",
      "question": "LLM에게 이메일 초안을 요청했는데 너무 길고 격식체로 나왔다. 원하는 결과를 얻으려면?",
      "options": [
        {
          "id": "A",
          "text": "더 성능 좋은 최신 모델로 교체한다"
        },
        {
          "id": "B",
          "text": "System prompt에 \"짧게 써줘\"라고 추가"
        },
        {
          "id": "C",
          "text": "\"3문장 이내, 친근한 톤\"처럼 조건 명시"
        },
        {
          "id": "D",
          "text": "출력 토큰 수를 100개로 강제 제한"
        }
      ],
      "correct_answer": "C",
      "explanation": "LLM은 명시하지 않은 속성(길이·톤·형식)을 임의로 결정합니다. 구체적 제약을 명시해야 의도한 결과가 나옵니다. 단순 토큰 제한은 문장 절단을 유발할 수 있습니다.",
      "learning_point": "좋은 프롬프트: 길이·톤·형식·포함/제외 항목을 구체적으로 제시."
    },
    "Q3": {
      "id": "Q3",
      "level": 2,
      "title": "Hallucination의 근본 원인",
      "question": "LLM이 \"아인슈타인이 2015년 노벨상을 받았다\"고 답했다. 이 Hallucination의 근본 원인은?",
      "options": [
        {
          "id": "A",
          "text": "학습 데이터에 잘못된 정보가 다수 포함되어 있음"
        },
        {
          "id": "B",
          "text": "모델 파라미터 수 부족으로 지식 저장 용량이 한계"
        },
        {
          "id": "C",
          "text": "다음 토큰 예측 방식이라 사실 무관하게 생성"
        },
        {
          "id": "D",
          "text": "입력 프롬프트가 너무 짧아서 맥락 파악에 실패"
        }
      ],
      "correct_answer": "C",
      "explanation": "LLM은 사실 데이터베이스가 아니라 확률적 생성기입니다. 통계적으로 자연스러운 다음 토큰을 예측하므로, 진위를 스스로 검증하지 않습니다.",
      "learning_point": "사실 검증은 외부 소스(검색/RAG/도구 호출)로 보강한다."
    },
    "Q4": {
      "id": "Q4",
      "level": 2,
      "title": "Temperature 이해",
      "question": "temperature=0으로 설정하면 어떤 현상이 발생하는가?",
      "options": [
        {
          "id": "A",
          "text": "가장 정확한 정보만 선택해 Hallucination 감소"
        },
        {
          "id": "B",
          "text": "모델이 더 신중히 검토해 답변 품질이 향상됨"
        },
        {
          "id": "C",
          "text": "응답 속도가 빨라지고 토큰 비용이 절감됨"
        },
        {
          "id": "D",
          "text": "재현성 높은 출력이 나오나, 정확성은 보장 안 됨"
        }
      ],
      "correct_answer": "D",
      "explanation": "temperature=0은 랜덤성을 최소화해 결정론적 디코딩에 가깝게 동작합니다. 단, top_p=1·샘플링 비활성 등 디코딩 설정이 동일하다는 전제가 필요하며, 정확성을 보장하진 않습니다.",
      "learning_point": "일관성(재현성)과 정확성은 별개 지표다."
    },
    "Q5": {
      "id": "Q5",
      "level": 2,
      "title": "프롬프트 기법 선택",
      "question": "고객사마다 다른 형식의 계약서를 우리 회사 표준 JSON으로 변환하려 한다. 가장 효과적인 프롬프트 전략은?",
      "options": [
        {
          "id": "A",
          "text": "Zero-shot: \"계약서를 JSON으로 변환해줘\""
        },
        {
          "id": "B",
          "text": "Few-shot: 3~4개의 변환 예시를 먼저 제공"
        },
        {
          "id": "C",
          "text": "Chain-of-Thought: 단계별 사고 과정 유도"
        },
        {
          "id": "D",
          "text": "Self-Consistency: 여러 번 생성 후 다수결"
        }
      ],
      "correct_answer": "B",
      "explanation": "형식 변환은 Few-shot 예시가 가장 직접적입니다. CoT/SC는 추론 정답형 문제에 유리합니다. (실무에선 JSON 모드/스키마 검증+재시도까지 결합하면 안정성이 크게 올라갑니다.)",
      "learning_point": "형식 학습=Few-shot, 구조화 출력=JSON 모드/스키마 검증."
    },
    "Q6": {
      "id": "Q6",
      "level": 2,
      "title": "RAG vs Fine-tuning",
      "question": "회사의 제품 매뉴얼이 매달 업데이트된다. 고객 질문에 최신 매뉴얼 기반으로 답변하는 AI를 만들려면?",
      "options": [
        {
          "id": "A",
          "text": "RAG: 매뉴얼을 벡터 DB에 저장 후 검색 제공"
        },
        {
          "id": "B",
          "text": "매달 새 매뉴얼로 모델을 Fine-tuning 재학습"
        },
        {
          "id": "C",
          "text": "System prompt에 전체 매뉴얼 내용을 포함"
        },
        {
          "id": "D",
          "text": "매뉴얼로 사전학습된 도메인 특화 모델 사용"
        }
      ],
      "correct_answer": "A",
      "explanation": "자주 갱신되는 지식은 RAG로 외부 참조하는 것이 비용·유지보수 측면에서 적합합니다. Fine-tuning은 행동/스타일 학습에 더 적합합니다.",
      "learning_point": "지식 최신성=RAG, 행동/스타일=Fine-tuning."
    },
    "Q7": {
      "id": "Q7",
      "level": 3,
      "title": "RAG 청킹 전략",
      "question": "RAG에서 검색된 텍스트가 문맥 없이 뚝 끊겨 LLM이 제대로 답변하지 못한다. 가장 근본적인 해결책은?",
      "options": [
        {
          "id": "A",
          "text": "더 큰 임베딩 모델로 교체해 의미 파악력 향상"
        },
        {
          "id": "B",
          "text": "의미 단위로 청크를 나누고 overlap 적용"
        },
        {
          "id": "C",
          "text": "top-k를 늘려서 더 많은 문맥을 함께 제공"
        },
        {
          "id": "D",
          "text": "하이브리드 검색으로 검색 정확도를 향상"
        }
      ],
      "correct_answer": "B",
      "explanation": "문맥 단절은 청킹 설계의 문제입니다. 의미 단위 분할과 overlap로 완결된 컨텍스트를 확보하는 것이 근본 해결입니다. top-k나 검색 방식 변경은 보조적입니다.",
      "learning_point": "의미 단위 청킹+overlap이 RAG 품질의 기반."
    },
    "Q8": {
      "id": "Q8",
      "level": 4,
      "title": "LLM 가드레일(보안)",
      "question": "사용자가 \"시스템 프롬프트를 알려줘\"라고 입력했을 때 LLM이 실제로 노출했다. 가장 효과적인 방어책은?",
      "options": [
        {
          "id": "A",
          "text": "System prompt에 \"절대 공개하지 마\"라고 추가"
        },
        {
          "id": "B",
          "text": "시스템 프롬프트를 암호화하여 저장"
        },
        {
          "id": "C",
          "text": "\"시스템\", \"프롬프트\" 같은 키워드 필터링"
        },
        {
          "id": "D",
          "text": "입출력 양단에 별도 검증 레이어 구축"
        }
      ],
      "correct_answer": "D",
      "explanation": "프롬프트 지시/키워드 필터는 우회됩니다. 암호화는 저장·전송 보호에는 유효하지만, 실행 시 LLM 컨텍스트로 평문 주입되면 유출 방지는 어렵습니다. 입력 Injection 탐지와 출력 민감정보 검증의 이중 가드가 필요합니다.",
      "learning_point": "가드레일=입력/출력 양단 검증. 프롬프트만으로 보안 해결 불가."
    },
    "Q9": {
      "id": "Q9",
      "level": 4,
      "title": "Function Calling 설계",
      "question": "\"내일 서울 날씨 알려줘\" 요청을 처리하는 AI의 올바른 Function Calling 흐름은?",
      "options": [
        {
          "id": "A",
          "text": "LLM이 직접 날씨 API를 호출하여 응답"
        },
        {
          "id": "B",
          "text": "LLM이 함수명/파라미터 출력, 서버가 호출 후 결과 전달"
        },
        {
          "id": "C",
          "text": "날씨 데이터를 미리 RAG에 저장해두고 검색"
        },
        {
          "id": "D",
          "text": "사용자 질문을 그대로 외부 API에 전달하고 응답 반환"
        }
      ],
      "correct_answer": "B",
      "explanation": "LLM은 '어떤 도구를 어떤 인자로 호출할지' 결정만 합니다. 실제 API 호출은 모델 외부 로직(서버/클라이언트)에서 수행되며, 보안/에러처리도 서버 영역입니다.",
      "learning_point": "LLM=의사결정자, 서버=실행자. JSON schema로 계약 정의."
    },
    "Q10": {
      "id": "Q10",
      "level": 4,
      "title": "Embedding 유사도와 동음이의어",
      "question": "RAG에서 \"자바 기초 문법\"을 검색했는데 \"인도네시아 자바섬 여행\"이 상위에 나왔다. 원인과 해결책은?",
      "options": [
        {
          "id": "A",
          "text": "동음이의어 미구분이 원인, 쿼리 맥락 추가나 리랭킹으로 해결"
        },
        {
          "id": "B",
          "text": "청크가 너무 작아 문맥 부족, 청크 크기 확대로 해결"
        },
        {
          "id": "C",
          "text": "벡터 유사도 임계값이 너무 낮음, 임계값 상향으로 해결"
        },
        {
          "id": "D",
          "text": "임베딩 차원 부족이 원인, 고차원 모델로 교체 필요"
        }
      ],
      "correct_answer": "A",
      "explanation": "동음이의어는 의미 분리 실패 케이스입니다. 쿼리 확장(예: 'Java 프로그래밍') 또는 Cross-encoder 리랭킹/메타데이터 필터/하이브리드 검색으로 해소합니다. 단순 임계값 조정은 근본 해결이 아닙니다.",
      "learning_point": "리랭킹·메타데이터 필터·하이브리드 검색으로 의미 분리."
    },
    "Q11": {
      "id": "Q11",
      "level": 5,
      "title": "AI Agent 자기 복구",
      "question": "AI Agent가 복잡한 작업 중 실패했을 때 스스로 복구하는 핵심 메커니즘은?",
      "options": [
        {
          "id": "A",
          "text": "더 큰 Context Window로 히스토리를 모두 기억"
        },
        {
          "id": "B",
          "text": "실패 시 처음부터 다시 시작하는 단순 retry 로직"
        },
        {
          "id": "C",
          "text": "관찰 결과 평가 후 실패 원인 추론해 계획 수정"
        },
        {
          "id": "D",
          "text": "여러 Agent를 병렬 실행하여 성공한 것을 선택"
        }
      ],
      "correct_answer": "C",
      "explanation": "Plan–Act–Observe(ReAct류) 루프에서 관찰/평가 후 계획을 수정하는 피드백이 핵심입니다. 여기에 자기반성(Reflexion/critic step)을 추가하면 복구율이 더 올라갑니다.",
      "learning_point": "관찰→평가→계획수정의 폐루프가 에이전트의 안정화 메커니즘."
    },
    "Q12": {
      "id": "Q12",
      "level": 5,
      "title": "Agent 메모리 설계",
      "question": "장기간 사용되는 AI Agent가 과거 대화를 효율적으로 활용하려면?",
      "options": [
        {
          "id": "A",
          "text": "모든 대화를 Context Window에 계속 누적"
        },
        {
          "id": "B",
          "text": "최근 N개 대화만 유지하고 나머지는 삭제"
        },
        {
          "id": "C",
          "text": "요약해 장기 메모리 저장, 필요 시 검색 추가"
        },
        {
          "id": "D",
          "text": "중요한 대화만 선별해 Fine-tuning 데이터로 활용"
        }
      ],
      "correct_answer": "C",
      "explanation": "무한 누적은 토큰/비용 문제가 있고, 단순 삭제는 손실이 큽니다. 요약+벡터 검색 기반 장기 메모리가 실무 표준입니다.",
      "learning_point": "Short-term(현재 대화)+Long-term(요약/검색) 하이브리드 메모리."
    },
    "Q13": {
      "id": "Q13",
      "level": 1,
      "title": "비용 제어 기본",
      "question": "LLM API 비용이 갑자기 폭증했다. 1차로 가장 먼저 점검할 항목은?",
      "options": [
        {
          "id": "A",
          "text": "temperature 파라미터 값"
        },
        {
          "id": "B",
          "text": "사용 중인 모델 버전"
        },
        {
          "id": "C",
          "text": "context 길이와 max_tokens 설정"
        },
        {
          "id": "D",
          "text": "프롬프트 톤 지시 내용"
        }
      ],
      "correct_answer": "C",
      "explanation": "토큰 소모가 비용을 좌우합니다. context 길이와 생성 토큰 상한을 관리하는 것이 1차 조치입니다.",
      "learning_point": "비용=토큰. 프롬프트/컨텍스트/출력 상한을 수치로 관리."
    },
    "Q14": {
      "id": "Q14",
      "level": 2,
      "title": "Fine-tuning vs RAG 선택",
      "question": "고객 응대 챗봇이 우리 회사만의 말투와 응대 스타일을 갖게 하려면?",
      "options": [
        {
          "id": "A",
          "text": "RAG로 응대 매뉴얼을 검색해 참조"
        },
        {
          "id": "B",
          "text": "Fine-tuning으로 말투/스타일 학습"
        },
        {
          "id": "C",
          "text": "System prompt에 말투 예시를 상세히 작성"
        },
        {
          "id": "D",
          "text": "더 큰 모델로 교체하면 자연스러워짐"
        }
      ],
      "correct_answer": "B",
      "explanation": "말투, 스타일 같은 행동 패턴은 Fine-tuning이 효과적입니다. RAG는 지식/정보 제공에 적합합니다.",
      "learning_point": "지식 업데이트=RAG, 행동/스타일 변경=Fine-tuning"
    },
    "Q15": {
      "id": "Q15",
      "level": 3,
      "title": "RAG 속도 최적화",
      "question": "RAG 서비스의 응답속도 병목을 줄이기 위한 1순위 전략은?",
      "options": [
        {
          "id": "A",
          "text": "임베딩 차원을 대폭 늘린다"
        },
        {
          "id": "B",
          "text": "캐시 키 설계로 중복 계산 제거"
        },
        {
          "id": "C",
          "text": "top-k 값을 크게 늘린다"
        },
        {
          "id": "D",
          "text": "모든 문서를 재임베딩한다"
        }
      ],
      "correct_answer": "B",
      "explanation": "적절한 캐시 키(정규화 쿼리+코퍼스 버전+파라미터)를 설계하면 동일 요청의 재계산을 제거하여 체감 지연을 크게 줄일 수 있습니다.",
      "learning_point": "캐시 키 설계=속도·비용 최적화의 핵심 지렛대."
    },
    "Q16": {
      "id": "Q16",
      "level": 4,
      "title": "Tool Call 루프 방지",
      "question": "에이전트가 Tool Call 무한 루프에 빠지는 것을 막는 핵심 설계는?",
      "options": [
        {
          "id": "A",
          "text": "seed 값을 고정하여 재현성 확보"
        },
        {
          "id": "B",
          "text": "top-p를 낮춰 출력 다양성 제한"
        },
        {
          "id": "C",
          "text": "context window를 크게 확장"
        },
        {
          "id": "D",
          "text": "state 가드와 최대 반복 깊이 제한"
        }
      ],
      "correct_answer": "D",
      "explanation": "상태 전이 가드, recursion depth 제한, 쿨다운/루프 탐지 규칙이 루프 방지의 본질입니다.",
      "learning_point": "플로우 제약(guardrail)으로 자율 시스템을 안전하게 통제."
    },
    "Q17": {
      "id": "Q17",
      "level": 5,
      "title": "멀티모달+RAG 응용",
      "question": "멀티모달 LLM을 RAG와 결합했을 때 가장 대표적인 응용은?",
      "options": [
        {
          "id": "A",
          "text": "이미지/비디오/텍스트 결합 검색형 QA"
        },
        {
          "id": "B",
          "text": "이미지에서 텍스트 추출 후 번역 자동화"
        },
        {
          "id": "C",
          "text": "음성 회의록을 요약하고 액션아이템 추출"
        },
        {
          "id": "D",
          "text": "차트 이미지를 분석해 수치 데이터 추출"
        }
      ],
      "correct_answer": "A",
      "explanation": "비전/오디오 인코더로 멀티모달 임베딩을 생성해 관련 증거를 검색·보강하는 QA가 대표적인 융합 시나리오입니다.",
      "learning_point": "멀티모달+RAG=근거 중심의 검색·요약·분석 확장."
    },
    "Q18": {
      "id": "Q18",
      "level": 6,
      "title": "Multimodal RAG 인덱싱",
      "question": "도면/스크린샷이 포함된 내부 문서를 대상으로 멀티모달 RAG를 설계한다. 가장 적절한 인덱싱 전략은?",
      "options": [
        {
          "id": "A",
          "text": "이미지 임베딩만 생성해 벡터DB에 저장"
        },
        {
          "id": "B",
          "text": "OCR/캡션 텍스트+비전 임베딩 이중 인덱스"
        },
        {
          "id": "C",
          "text": "텍스트만 임베딩하고 이미지는 제외"
        },
        {
          "id": "D",
          "text": "모든 이미지를 Base64로 프롬프트 첨부"
        }
      ],
      "correct_answer": "B",
      "explanation": "멀티모달 RAG에서는 텍스트화된 신호(OCR/캡션)를 기본으로, 필요 시 이미지 임베딩 이중 인덱스로 보완하는 전략이 일반적입니다.",
      "learning_point": "텍스트/비전 이중 인덱싱과 쿼리-모달리티 정렬이 품질의 핵심."
    },
    "Q19": {
      "id": "Q19",
      "level": 6,
      "title": "AI 안전 시스템 설계",
      "question": "AI 챗봇의 유해 응답을 필터링하는 안전 시스템을 설계할 때, 1차 필터의 설계 원칙으로 가장 적절한 것은?",
      "options": [
        {
          "id": "A",
          "text": "Precision 최대화로 정상 응답 차단 최소화"
        },
        {
          "id": "B",
          "text": "응답 속도를 최우선하여 필터 간소화"
        },
        {
          "id": "C",
          "text": "단일 모델로 모든 유해 유형을 한번에 판단"
        },
        {
          "id": "D",
          "text": "Recall 우선으로 의심 케이스 포착 후 2차 정밀 검증"
        }
      ],
      "correct_answer": "D",
      "explanation": "안전 시스템에서는 유해 콘텐츠를 놓치지 않는 것(높은 Recall)이 1차 목표입니다. 이후 2차에서 Precision을 높여 오탐을 줄입니다.",
      "learning_point": "안전/컴플라이언스=고리콜 1차 + 고프리시전 2차(캐스케이드)."
    },
    "Q20": {
      "id": "Q20",
      "level": 3,
      "title": "하이브리드 검색 트리거",
      "question": "상품코드, 오류번호처럼 정확히 일치해야 하는 텍스트가 많을 때, 벡터 검색만 사용하면 검색 정확도가 떨어진다. 가장 적절한 보완은?",
      "options": [
        {
          "id": "A",
          "text": "임베딩 차원을 늘려 표현력 향상"
        },
        {
          "id": "B",
          "text": "임베딩 모델을 더 큰 것으로 교체"
        },
        {
          "id": "C",
          "text": "top-k를 크게 늘려 후보 확대"
        },
        {
          "id": "D",
          "text": "BM25 + 벡터 하이브리드 검색 적용"
        }
      ],
      "correct_answer": "D",
      "explanation": "희소 토큰/정확 매칭은 키워드 검색이 강점이므로 벡터와 결합한 하이브리드가 정석입니다.",
      "learning_point": "정확 매칭 신호(키워드)와 의미 검색(벡터)을 조합."
    },
    "Q21": {
      "id": "Q21",
      "level": 3,
      "title": "실시간 문서 업데이트 처리",
      "question": "매일 대량의 문서가 추가/삭제되는 RAG 시스템에서 검색 품질을 유지하려면?",
      "options": [
        {
          "id": "A",
          "text": "실시간 색인 갱신을 지원하는 벡터DB 사용"
        },
        {
          "id": "B",
          "text": "매일 밤 전체 색인을 새로 구축"
        },
        {
          "id": "C",
          "text": "문서 변경을 무시하고 주간 단위로 갱신"
        },
        {
          "id": "D",
          "text": "변경된 문서만 별도 DB에 저장 후 병합 검색"
        }
      ],
      "correct_answer": "A",
      "explanation": "동적으로 문서가 변하는 환경에서는 실시간 색인 갱신(upsert/delete)을 지원하는 벡터DB가 필수입니다.",
      "learning_point": "동적 코퍼스=HNSW 계열, 정적 대규모=IVF/PQ 고려."
    },
    "Q22": {
      "id": "Q22",
      "level": 3,
      "title": "Retriever 평가 지표",
      "question": "RAG의 Retriever 단만 분리 평가할 때 핵심 지표는?",
      "options": [
        {
          "id": "A",
          "text": "Recall@k (상위 k개 중 정답 포함 비율)"
        },
        {
          "id": "B",
          "text": "ROUGE-L (생성 텍스트 유사도)"
        },
        {
          "id": "C",
          "text": "BLEU (번역 품질 점수)"
        },
        {
          "id": "D",
          "text": "Perplexity (언어모델 혼란도)"
        }
      ],
      "correct_answer": "A",
      "explanation": "Retriever는 관련 문서를 얼마나 놓치지 않고 가져오는지가 핵심이므로 Recall@k가 1차 지표입니다.",
      "learning_point": "Retriever=Recall 중심, Generator=Faithfulness/Answer Relevancy."
    },
    "Q23": {
      "id": "Q23",
      "level": 4,
      "title": "Structured Output 강제",
      "question": "LLM에게 표준 JSON 스키마를 엄격히 따르게 하는 실무적 방법으로 가장 적절한 것은?",
      "options": [
        {
          "id": "A",
          "text": "\"JSON으로 출력해\"라고만 지시하기"
        },
        {
          "id": "B",
          "text": "system prompt에 스키마 평문 첨부만"
        },
        {
          "id": "C",
          "text": "temperature=0으로 설정하여 고정"
        },
        {
          "id": "D",
          "text": "Tool Calling + 스키마 검증/재시도 루프"
        }
      ],
      "correct_answer": "D",
      "explanation": "스키마를 계약으로 강제하고 서버 검증/재시도를 결합해야 안정적입니다.",
      "learning_point": "스키마 계약+검증+재시도=구조화 출력의 표준 패턴."
    },
    "Q24": {
      "id": "Q24",
      "level": 4,
      "title": "Function Call 에러 회복",
      "question": "외부 API가 502를 반환하고 tool 응답 JSON 스키마가 깨졌다. 올바른 회복 절차는?",
      "options": [
        {
          "id": "A",
          "text": "LLM에 \"다른 방법 찾아봐\"라고만 지시"
        },
        {
          "id": "B",
          "text": "서버가 재시도 후 실패 사유를 LLM에 전달, 리플랜 유도"
        },
        {
          "id": "C",
          "text": "사용자에게 입력 변경을 요구하고 대기"
        },
        {
          "id": "D",
          "text": "동일 요청을 지연 없이 즉시 반복 시도"
        }
      ],
      "correct_answer": "B",
      "explanation": "툴 실패는 서버 책임으로 처리(재시도/타임아웃/폴백) 후 사유를 LLM 컨텍스트에 반영해 리플래닝을 유도합니다.",
      "learning_point": "서버=실행/회복, LLM=의사결정; 실패 사유를 모델에 피드백."
    },
    "Q25": {
      "id": "Q25",
      "level": 4,
      "title": "리랭킹 적용 위치",
      "question": "Cross-encoder 기반 리랭킹은 어느 지점에 적용하는 것이 일반적이고 효율적인가?",
      "options": [
        {
          "id": "A",
          "text": "전체 코퍼스에 대해 전수 리랭킹 수행"
        },
        {
          "id": "B",
          "text": "프롬프트에 \"리랭킹해줘\"라고 지시함"
        },
        {
          "id": "C",
          "text": "LLM 생성 후 최종 답변에 사후 적용"
        },
        {
          "id": "D",
          "text": "베이스 retriever top-k 후보에만 적용"
        }
      ],
      "correct_answer": "D",
      "explanation": "Cross-encoder는 비용이 커서 1차 후보군에만 적용하는 2-stage 검색이 일반적입니다.",
      "learning_point": "2단계(베이스→리랭크)로 품질/비용 균형."
    }
  }
}